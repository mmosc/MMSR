{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables that contains the file location\n",
    "import datatable as dt\n",
    "\n",
    "# Variables that contains the file location\n",
    "from files import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = file_blf_vardeltaspectral"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = dt.fread(file)\n",
    "df[dt.float64] = dt.float32  # compress\n",
    "df = df.to_pandas()\n",
    "df.set_index('id', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# string ids are inefficient, let's use integers and a lookup table\n",
    "id_to_key = df.index.values\n",
    "key_to_id = dict(zip(id_to_key, list(range(len(df.index.values)))))\n",
    "indices = np.arange(len(id_to_key))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Similarity Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_cosine_similarity(arr_a, arr_b):\n",
    "    norms_a = np.linalg.norm(arr_a, axis=-1)[:, np.newaxis]\n",
    "    norms_b = np.linalg.norm(arr_b, axis=-1)[:, np.newaxis]\n",
    "    divisor = norms_a * norms_b.T\n",
    "    dot_p = arr_a @ arr_b.T\n",
    "    return np.divide(dot_p, divisor, dot_p, where=divisor > 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_in_batches_distance(arr: np.array, sim_function, batches: int = 1):\n",
    "    \"\"\"\n",
    "    :param arr: full Data array\n",
    "    :param sim_function: similarity function, receiving two 2 dimensional data matrices\n",
    "    :param batches: split arr into chunks for less RAM usage\n",
    "    :return: the full similarity matrix\n",
    "    \"\"\"\n",
    "    splits = np.array_split(arr, batches, axis=0)\n",
    "    r = np.zeros((len(arr),) * 2, dtype=np.float32)\n",
    "    y = 0\n",
    "    for b in tqdm(splits):\n",
    "        r[:, y:y + b.shape[0]] = sim_function(arr, b)\n",
    "        y += b.shape[0]\n",
    "    return r"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_in_batches_top_ids(results: np.array, idx_values: np.array, top: int = -1, batches: int = 1):\n",
    "    \"\"\"\n",
    "    :param results: a similarity matrix\n",
    "    :param idx_values: the indices\n",
    "    :param top: how many ids should get retrieved\n",
    "    :param batches: split arr into chunks for less RAM usage\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if top < 0:\n",
    "        top = len(results)\n",
    "    splits = np.array_split(results, batches, axis=0)\n",
    "    ids = np.zeros((len(results), top), dtype=np.int32)\n",
    "    y = 0\n",
    "    for b in tqdm(splits):\n",
    "        ids[y:y + b.shape[0], :] = idx_values[np.argsort(b * -1, axis=1)][:, :top]\n",
    "        y += b.shape[0]\n",
    "    return ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the similarity matrix\n",
    "result = compute_in_batches_distance(df.to_numpy(), sim_function=get_cosine_similarity, batches=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optionally save the entire matrix\n",
    "# np.save(\"example_similarity_matrix.npy\", result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# result = np.load(\"example_similarity_matrix.npy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# normalize, if used for late fusion\n",
    "np.subtract(result, result.mean(), out=result)\n",
    "\n",
    "# np.std requires a temporary matrix, on the full results this would kill the ram\n",
    "np.divide(result, result[::64, ::64].std(), out=result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[3::128, 3::128].std()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# replace diagonals by 0 to prevent them being picked\n",
    "np.fill_diagonal(result, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate\n",
    "top_ids = compute_in_batches_top_ids(result, indices, batches=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the results\n",
    "np.save(\"top_ids.npy\", top_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checkpoint\n",
    "Here you can restart the Kernel in case your machine runs with less than 64 GB of memory\n",
    "Make sure to run the first few cells again"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    top_ids\n",
    "except NameError:\n",
    "    top_ids = np.load(\"top_ids.npy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the genres\n",
    "genres = dt.fread(file_genres_2).to_pandas()\n",
    "genres.set_index('id', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_ids_df = pd.DataFrame(top_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert string ids to integer ids\n",
    "genres_index = np.asarray([key_to_id[i] for i in genres.index.values])\n",
    "genres = genres.set_index(genres_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# and evaluate our results\n",
    "getMetrics(top_ids_df, 100, genres)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correlation\n",
    "we only calculated one top ids result here, so this is only a dummy example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "correlation = np.zeros((len(top_ids_df),))\n",
    "for i in tqdm(indices):\n",
    "    correlation[i] = scipy.stats.kendalltau(top_ids_df.loc[i].values, top_ids_df.loc[i].values)[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlation.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additional hints and research results\n",
    "* Instead of string ids, use integers to reduce memory usage of top ids\n",
    "* Memory allocation overhead can be reduced inside the similarity function\n",
    "* Norms could be cached\n",
    "* When splitting results, then deleting results, then processing top ids while deleting the old splits top id calculation could be done \"in place\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
