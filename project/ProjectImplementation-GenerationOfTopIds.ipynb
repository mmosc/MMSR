{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from tqdm import tqdm\n",
    "# from numba import jit\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>addict</th>\n",
       "      <th>afraid</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahead</th>\n",
       "      <th>...</th>\n",
       "      <th>yea</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9jbSytob9XRzwvB6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Njp6JPM8vitbhVJU</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h48f46ZsT9h0Z5Dm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZmXVK43zlqdeq6z8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV5EXN6AIVBqvsLO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  abl  accept  across  act  addict    afraid  age  ago   ah  \\\n",
       "id                                                                            \n",
       "9jbSytob9XRzwvB6  0.0     0.0     0.0  0.0     0.0  0.000000  0.0  0.0  0.0   \n",
       "Njp6JPM8vitbhVJU  0.0     0.0     0.0  0.0     0.0  0.000000  0.0  0.0  0.0   \n",
       "h48f46ZsT9h0Z5Dm  0.0     0.0     0.0  0.0     0.0  0.000000  0.0  0.0  0.0   \n",
       "ZmXVK43zlqdeq6z8  0.0     0.0     0.0  0.0     0.0  0.000000  0.0  0.0  0.0   \n",
       "PV5EXN6AIVBqvsLO  0.0     0.0     0.0  0.0     0.0  0.327025  0.0  0.0  0.0   \n",
       "\n",
       "                  ahead  ...  yea  yeah  year  yellow  yes  yesterday  yet  \\\n",
       "id                       ...                                                 \n",
       "9jbSytob9XRzwvB6    0.0  ...  0.0   0.0   0.0     0.0  0.0   0.000000  0.0   \n",
       "Njp6JPM8vitbhVJU    0.0  ...  0.0   0.0   0.0     0.0  0.0   0.000000  0.0   \n",
       "h48f46ZsT9h0Z5Dm    0.0  ...  0.0   0.0   0.0     0.0  0.0   0.149783  0.0   \n",
       "ZmXVK43zlqdeq6z8    0.0  ...  0.0   0.0   0.0     0.0  0.0   0.000000  0.0   \n",
       "PV5EXN6AIVBqvsLO    0.0  ...  0.0   0.0   0.0     0.0  0.0   0.000000  0.0   \n",
       "\n",
       "                   yo  young     youth  \n",
       "id                                      \n",
       "9jbSytob9XRzwvB6  0.0    0.0  0.150511  \n",
       "Njp6JPM8vitbhVJU  0.0    0.0  0.000000  \n",
       "h48f46ZsT9h0Z5Dm  0.0    0.0  0.000000  \n",
       "ZmXVK43zlqdeq6z8  0.0    0.0  0.000000  \n",
       "PV5EXN6AIVBqvsLO  0.0    0.0  0.000000  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = pd.read_table(\"./../MMSR_WT22_Task1_Data/id_lyrics_tf-idf_mmsr.tsv\", index_col='id')\n",
    "tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Feature vectors to use\n",
    "word2vec = pd.read_table(\"./../MMSR_WT22_Task1_Data/id_lyrics_word2vec_mmsr.tsv\", index_col='id')\n",
    "bert = pd.read_table(\"./../MMSR_WT22_Task1_Data/id_bert_mmsr.tsv\", index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = pd.read_table(\"./../MMSR_WT22_Task1_Data/id_genres_mmsr.tsv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_table(\"./../MMSR_WT22_Task1_Data/id_information_mmsr.tsv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New solution, with hardcoded cosine similarity and df\n",
    "\n",
    "def get_cosine_similarity(arr_a: np.array, arr_b: np.array):\n",
    "    def func(d1, d2, divisor):\n",
    "        return np.divide(d1 @ d2, divisor, np.zeros_like(divisor), where=divisor > 0)\n",
    "\n",
    "    norms_a = np.linalg.norm(arr_a, axis=-1)\n",
    "    norms_b = np.linalg.norm(arr_b, axis=-1) # todo why doesn't norms[indicies_test] work here?\n",
    "\n",
    "    r = np.zeros((len(arr_a), len(arr_b)))\n",
    "    for index, sample in enumerate(tqdm(arr_b)):\n",
    "        r[:, index] = func(arr_a, sample, norms_a * norms_b[index])\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(d1, d2):\n",
    "    divisor = np.linalg.norm(d1) * np.linalg.norm(d2)\n",
    "    if divisor == 0:\n",
    "        return 0\n",
    "    return (d1 @ d2) / divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some calculations\n",
    "# print(\n",
    "#     cosine_similarity(tf_idf.iloc[0].values, tf_idf.iloc[2].values),\n",
    "#     cosine_similarity(tf_idf.iloc[0].values, tf_idf.iloc[3].values)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_innerProduct_similarity(arr_a: np.array, arr_b: np.array):\n",
    "    r = np.zeros((len(arr_a), len(arr_b)))\n",
    "    for index, sample in enumerate(tqdm(arr_b)):\n",
    "        r[:, index] = arr_a @ sample \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(d1, d2):\n",
    "    return (d1 @ d2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I am not sure if it is correct\n",
    "def jaccard_formulation(d1, d2):\n",
    "    divisor = np.linalg.norm(d1) + np.linalg.norm(d2) - (d1 @ d2)\n",
    "    if divisor == 0:\n",
    "        return 0\n",
    "    return (d1 @ d2) / divisor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New solution, with hardcoded cosine similarity and df\n",
    "\n",
    "def get_jaccard_similarity(arr_a: np.array, arr_b: np.array):\n",
    "    def func(d1, d2, divisor):\n",
    "        d1_d2_product = d1 @ d2\n",
    "        return np.divide(d1_d2_product, divisor - d1_d2_product, np.zeros_like(divisor), where=divisor > 0)\n",
    "\n",
    "    norms_a = np.linalg.norm(arr_a, axis=-1)\n",
    "    norms_b = np.linalg.norm(arr_b, axis=-1) # todo why doesn't norms[indicies_test] work here?\n",
    "\n",
    "    r = np.zeros((len(arr_a), len(arr_b)))\n",
    "    for index, sample in enumerate(tqdm(arr_b)):\n",
    "        r[:, index] = func(arr_a, sample, norms_a + norms_b[index])\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongIdByQuery(query):\n",
    "    artist, track =query.split(',')\n",
    "    id_ = info[(info['artist'] == artist) & (info['song'] == track)].index.values[0]\n",
    "    return id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topIdsQueries(dfQueries, topNumber):\n",
    "    top_idsongs = pd.DataFrame(index=dfQueries.columns.values, columns=range(topNumber))\n",
    "    for query in tqdm(dfQueries.columns.values): # For each query done\n",
    "        top = dfQueries[query].sort_values(ascending=False).drop(axis=0, index=[query]).head(topNumber) # Top n songs values\n",
    "        top_idsongs.loc[query] = top.index.values\n",
    "    return top_idsongs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 100 Ids using each song as a query with cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF -- Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [37:24<00:00, 33.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_cosine_similarity(tf_idf.to_numpy(), tf_idf.to_numpy())\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(data=result.T ,index=tf_idf.index.values, columns=tf_idf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [35:05<00:00, 36.16it/s]\n"
     ]
    }
   ],
   "source": [
    "topIdsQueries(df_test, 100).to_csv('./topIds/top_ids_cosine_tfidf_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec -- Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [13:56<00:00, 91.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = get_cosine_similarity(word2vec.to_numpy(), word2vec.to_numpy())\n",
    "print(result2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = pd.DataFrame(data=result2.T ,index=word2vec.index.values, columns=word2vec.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [21:56<00:00, 57.81it/s]\n"
     ]
    }
   ],
   "source": [
    "topIdsQueries(df_test2, 100).to_csv('./topIds/top_ids_cosine_word2vec_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert -- Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [28:33<00:00, 44.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result3 = get_cosine_similarity(bert.to_numpy(), bert.to_numpy())\n",
    "print(result3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test3 = pd.DataFrame(data=result3.T ,index=bert.index.values, columns=bert.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [23:03<00:00, 55.03it/s]\n"
     ]
    }
   ],
   "source": [
    "topIdsQueries(df_test3, 100).to_csv('./topIds/top_ids_cosine_bert_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only compare with first 100 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceToSongs(idSong, similarity_function, df, features_vector):\n",
    "    if idSong in df.columns.values:\n",
    "        print(\"Already in data\")\n",
    "    else:\n",
    "        songs = features_vector.index.values\n",
    "        distances = [similarity_function(features_vector.loc[idSong], features_vector.loc[song]) for index,song in enumerate(songs)]\n",
    "        df[idSong]  = distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [22:28<00:00, 13.48s/it]\n"
     ]
    }
   ],
   "source": [
    "index_values = tf_idf.index\n",
    "df_cosineDistance_tfidf = pd.DataFrame(index=index_values)\n",
    "\n",
    "for id_ in tqdm(tf_idf.index.values[:100]):\n",
    "    distanceToSongs(id_, cosine_similarity, df_cosineDistance_tfidf, tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [17:40<00:00, 10.60s/it]\n"
     ]
    }
   ],
   "source": [
    "index_values = word2vec.index\n",
    "df_cosineDistance_word2vec = pd.DataFrame(index=index_values)\n",
    "\n",
    "for id_ in tqdm(word2vec.index.values[:100]):\n",
    "    distanceToSongs(id_, cosine_similarity, df_cosineDistance_word2vec, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [21:05<00:00, 12.66s/it]\n"
     ]
    }
   ],
   "source": [
    "index_values = bert.index\n",
    "df_cosineDistance_bert = pd.DataFrame(index=index_values)\n",
    "\n",
    "for id_ in tqdm(bert.index.values[:100]):\n",
    "    distanceToSongs(id_, cosine_similarity, df_cosineDistance_bert, bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cosineDistance_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 100 Ids using each song as a query with jaccard similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF -- Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [39:14<00:00, 32.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_jaccard_similarity(tf_idf.to_numpy(), tf_idf.to_numpy())\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_jaccard_similarity(tf_idf.to_numpy(), tf_idf[:3].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(data=result.T ,index=tf_idf.index.values, columns=tf_idf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [28:46<00:00, 44.08it/s]\n"
     ]
    }
   ],
   "source": [
    "topIdsQueries(df_test, 100).to_csv('./topIds/top_ids_jaccard_tfidf_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec -- Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [15:30<00:00, 81.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = get_jaccard_similarity(word2vec.to_numpy(), word2vec.to_numpy())\n",
    "print(result2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = pd.DataFrame(data=result2.T ,index=word2vec.index.values, columns=word2vec.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [28:16<00:00, 44.88it/s]\n"
     ]
    }
   ],
   "source": [
    "topIdsQueries(df_test2, 100).to_csv('./topIds/top_ids_jaccard_word2vec_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert -- Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [29:01<00:00, 43.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result3 = get_jaccard_similarity(bert.to_numpy(), bert.to_numpy())\n",
    "print(result3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test3 = pd.DataFrame(data=result3.T ,index=bert.index.values, columns=bert.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [34:07<00:00, 37.18it/s]\n"
     ]
    }
   ],
   "source": [
    "topIdsQueries(df_test3, 100).to_csv('./topIds/top_ids_jaccard_bert_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 100 Ids using each song as a query with jaccard similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF -- Inner Product Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [36:12<00:00, 35.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [25:08<00:00, 50.47it/s]\n"
     ]
    }
   ],
   "source": [
    "result = get_innerProduct_similarity(tf_idf.to_numpy(), tf_idf.to_numpy())\n",
    "print(result.shape)\n",
    "df_test = pd.DataFrame(data=result.T ,index=tf_idf.index.values, columns=tf_idf.index)\n",
    "topIdsQueries(df_test, 100).to_csv('./topIds/top_ids_innerProduct_tfidf_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec --  Inner Product Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [14:00<00:00, 90.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [34:16<00:00, 37.02it/s]\n"
     ]
    }
   ],
   "source": [
    "result2 = get_innerProduct_similarity(word2vec.to_numpy(), word2vec.to_numpy())\n",
    "print(result2.shape)\n",
    "df_test2 = pd.DataFrame(data=result2.T ,index=word2vec.index.values, columns=word2vec.index)\n",
    "topIdsQueries(df_test2, 100).to_csv('./topIds/top_ids_innerProduct_word2vec_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert --  Inner Product Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [30:20<00:00, 41.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76115, 76115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76115/76115 [28:01<00:00, 45.26it/s]\n"
     ]
    }
   ],
   "source": [
    "result3 = get_innerProduct_similarity(bert.to_numpy(), bert.to_numpy())\n",
    "print(result3.shape)\n",
    "df_test3 = pd.DataFrame(data=result3.T ,index=bert.index.values, columns=bert.index)\n",
    "topIdsQueries(df_test3, 100).to_csv('./topIds/top_ids_innerProduct_bert_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
